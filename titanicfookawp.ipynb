{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-29T10:21:23.812261Z",
     "iopub.status.busy": "2025-10-29T10:21:23.812022Z",
     "iopub.status.idle": "2025-10-29T10:21:24.572301Z",
     "shell.execute_reply": "2025-10-29T10:21:24.571407Z",
     "shell.execute_reply.started": "2025-10-29T10:21:23.812242Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk(\"/kaggle/input\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "file_train_data = \"data/train.csv\"\n",
    "file_test_data = \"data/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T10:30:25.431024Z",
     "iopub.status.busy": "2025-10-29T10:30:25.430630Z",
     "iopub.status.idle": "2025-10-29T10:30:25.442571Z",
     "shell.execute_reply": "2025-10-29T10:30:25.441503Z",
     "shell.execute_reply.started": "2025-10-29T10:30:25.430994Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'PassengerId': '1', 'Survived': '0', 'Pclass': '3', 'Name': 'Braund, Mr. Owen Harris', 'Sex': 'male', 'Age': '22', 'SibSp': '1', 'Parch': '0', 'Ticket': 'A/5 21171', 'Fare': '7.25', 'Cabin': '', 'Embarked': 'S'}, {'PassengerId': '2', 'Survived': '1', 'Pclass': '1', 'Name': 'Cumings, Mrs. John Bradley (Florence Briggs Thayer)', 'Sex': 'female', 'Age': '38', 'SibSp': '1', 'Parch': '0', 'Ticket': 'PC 17599', 'Fare': '71.2833', 'Cabin': 'C85', 'Embarked': 'C'}, {'PassengerId': '3', 'Survived': '1', 'Pclass': '3', 'Name': 'Heikkinen, Miss. Laina', 'Sex': 'female', 'Age': '26', 'SibSp': '0', 'Parch': '0', 'Ticket': 'STON/O2. 3101282', 'Fare': '7.925', 'Cabin': '', 'Embarked': 'S'}]\n",
      "[{'PassengerId': '892', 'Pclass': '3', 'Name': 'Kelly, Mr. James', 'Sex': 'male', 'Age': '34.5', 'SibSp': '0', 'Parch': '0', 'Ticket': '330911', 'Fare': '7.8292', 'Cabin': '', 'Embarked': 'Q'}, {'PassengerId': '893', 'Pclass': '3', 'Name': 'Wilkes, Mrs. James (Ellen Needs)', 'Sex': 'female', 'Age': '47', 'SibSp': '1', 'Parch': '0', 'Ticket': '363272', 'Fare': '7', 'Cabin': '', 'Embarked': 'S'}, {'PassengerId': '894', 'Pclass': '2', 'Name': 'Myles, Mr. Thomas Francis', 'Sex': 'male', 'Age': '62', 'SibSp': '0', 'Parch': '0', 'Ticket': '240276', 'Fare': '9.6875', 'Cabin': '', 'Embarked': 'Q'}]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "train_csv = []\n",
    "with open(file_train_data, \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "\n",
    "    for row in reader:\n",
    "        train_csv.append(row)\n",
    "\n",
    "print(train_csv[:3])\n",
    "\n",
    "test_csv = []\n",
    "with open(file_test_data, \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "\n",
    "    for row in reader:\n",
    "        test_csv.append(row)\n",
    "\n",
    "print(test_csv[:3])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T10:42:10.956467Z",
     "iopub.status.busy": "2025-10-29T10:42:10.956171Z",
     "iopub.status.idle": "2025-10-29T10:42:10.965620Z",
     "shell.execute_reply": "2025-10-29T10:42:10.964842Z",
     "shell.execute_reply.started": "2025-10-29T10:42:10.956447Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': '1', 'input': [1.0, 0.0, 0.275, 0.125, 0.0, 0.014151057562208049, 0.0], 'output': [0.0]}, {'id': '2', 'input': [0.0, 1.0, 0.475, 0.125, 0.0, 0.13913573538264068, 0.3333333333333333], 'output': [1.0]}, {'id': '3', 'input': [1.0, 1.0, 0.325, 0.0, 0.0, 0.015468569817999833, 0.0], 'output': [1.0]}]\n",
      "[{'id': '892', 'input': [1.0, 0.0, 0.45394736842105265, 0.0, 0.0, 0.015281580671177828, 1.0], 'output': [0.0]}, {'id': '893', 'input': [1.0, 1.0, 0.618421052631579, 0.125, 0.0, 0.013663090060062943, 0.0], 'output': [0.0]}, {'id': '894', 'input': [0.5, 0.0, 0.8157894736842105, 0.0, 0.0, 0.018908740708122825, 1.0], 'output': [0.0]}]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "def parse_data(lines):\n",
    "    # First we filter out the data we need\n",
    "    data = []\n",
    "    for l in lines:\n",
    "        data.append(\n",
    "            {\n",
    "                \"id\": l[\"PassengerId\"],\n",
    "                \"survived\": l.get(\"Survived\", 0),\n",
    "                \"class\": l[\"Pclass\"],\n",
    "                \"sex\": l[\"Sex\"],\n",
    "                \"age\": l[\"Age\"],\n",
    "                \"sibsp\": l[\"SibSp\"],\n",
    "                \"parch\": l[\"Parch\"],\n",
    "                \"fare\": l.get(\"Fare\", 0),\n",
    "                \"embarked\": l[\"Embarked\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Normalize data\n",
    "    norm_sex = {\"male\": 0, \"female\": 1}\n",
    "    norm_embarked = {\"S\": 0, \"C\": 1, \"Q\": 2, \"\": 3}\n",
    "\n",
    "    normalized_data = []\n",
    "    # Numberize values\n",
    "    for row in data:\n",
    "        # Check for errors\n",
    "        if norm_sex.get(row[\"sex\"], \"unknown\") == \"unknown\":\n",
    "            print(row[\"id\"], row[\"sex\"])\n",
    "        if norm_embarked.get(row[\"embarked\"], \"unknown\") == \"unknown\":\n",
    "            print(row[\"id\"], row[\"embarked\"])\n",
    "\n",
    "        nd = copy.deepcopy(row)\n",
    "\n",
    "        nd[\"sex\"] = norm_sex[row[\"sex\"]]\n",
    "        nd[\"fare\"] = float(row[\"fare\"]) if row[\"fare\"] != \"\" else 0\n",
    "        nd[\"embarked\"] = norm_embarked[row[\"embarked\"]]\n",
    "        nd[\"age\"] = float(row[\"age\"]) if row[\"age\"] != \"\" else 0\n",
    "\n",
    "        normalized_data.append(nd)\n",
    "\n",
    "\n",
    "    keys = list(normalized_data[0].keys())\n",
    "\n",
    "    # Extract min max of each key\n",
    "    keys_minmax = {}\n",
    "    for k in keys:\n",
    "        values = [d[k] for d in normalized_data if k in d]\n",
    "        # print(values)\n",
    "        min_value, max_value = float(min(values)), float(max(values))\n",
    "        keys_minmax[k] = {\"min\": min_value, \"max\": max_value}\n",
    "\n",
    "    # Normalize 0 to 1 all keys\n",
    "    for r in normalized_data:\n",
    "        for k in keys:\n",
    "            if k == \"id\":\n",
    "                continue\n",
    "            value = float(r[k])\n",
    "            minmax = keys_minmax[k]\n",
    "            norm_value = (value - minmax[\"min\"]) / (minmax[\"max\"] - minmax[\"min\"]) if (minmax[\"max\"] - minmax[\"min\"]) != 0 else 0.0\n",
    "            r[k] = norm_value\n",
    "            # print(keys_minmax[k], value, norm_value)\n",
    "\n",
    "    # Split data into input -> expected output\n",
    "    train_data = []\n",
    "    for r in normalized_data:\n",
    "        train_data.append(\n",
    "            {\n",
    "                \"id\": r[\"id\"],\n",
    "                \"input\": list(\n",
    "                    {k: v for k, v in r.items() if k not in [\"survived\", \"id\"]}.values()\n",
    "                ),\n",
    "                \"output\": [r[\"survived\"]],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return train_data\n",
    "\n",
    "train_data = parse_data(train_csv)\n",
    "print(train_data[:3])\n",
    "\n",
    "test_data = parse_data(test_csv)\n",
    "print(test_data[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T11:11:45.045237Z",
     "iopub.status.busy": "2025-10-29T11:11:45.044884Z",
     "iopub.status.idle": "2025-10-29T11:11:45.056497Z",
     "shell.execute_reply": "2025-10-29T11:11:45.055453Z",
     "shell.execute_reply.started": "2025-10-29T11:11:45.045206Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "# Determine the best available device\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# DEVICE = torch.device(\"cpu\")\n",
    "DEVICE = get_device()\n",
    "\n",
    "\n",
    "class SimpleNeuralNetwork(nn.Module):\n",
    "    \"\"\"Simple feedforward neural network using PyTorch\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int = 16,\n",
    "        hidden_layers: List[int] = [256],\n",
    "        output_size: int = 4,\n",
    "        empty: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if empty:\n",
    "            return\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # Build layers using PyTorch modules\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "\n",
    "        # Add hidden layers\n",
    "        for hidden_size in hidden_layers:\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            # layers.append(nn.Sigmoid())\n",
    "            prev_size = hidden_size\n",
    "\n",
    "        # Add output layer (no activation)\n",
    "        layers.append(nn.Linear(prev_size, output_size))\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "        # Initialize weights using He initialization\n",
    "        self._initialize_weights()\n",
    "\n",
    "        # Move to device\n",
    "        self.to(DEVICE)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights using He initialization\"\"\"\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.kaiming_normal_(module.weight, nonlinearity=\"tanh\")\n",
    "                nn.init.zeros_(module.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the network\"\"\"\n",
    "        # Convert numpy array to tensor if needed and move to device\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.from_numpy(x).float().to(DEVICE)\n",
    "        elif isinstance(x, torch.Tensor):\n",
    "            x = x.to(DEVICE)\n",
    "        elif isinstance(x, list):\n",
    "            x = torch.tensor(x, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "        return self.network(x)\n",
    "\n",
    "    def mutate(self, mutation_rate: float = 0.1, mutation_strength: float = 0.5):\n",
    "        \"\"\"Mutate the network's weights and biases\"\"\"\n",
    "        with torch.no_grad():\n",
    "            for param in self.parameters():\n",
    "                if torch.rand(1).item() < mutation_rate:\n",
    "                    mutation = torch.randn_like(param) * mutation_strength\n",
    "                    param.add_(mutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "from typing import List\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "class EvolutionaryOptimizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        population_size: int = 50,\n",
    "        elite_size: int = 10,\n",
    "        new_members: int = 0,\n",
    "        mutation_rate: float = 0.1,\n",
    "        mutation_strength: float = 0.5,\n",
    "        input_size: int = 8,\n",
    "        hidden_layers: List[int] = [32],\n",
    "        output_size: int = 1,\n",
    "        train_data: List = [],\n",
    "    ):\n",
    "        self.population_size = population_size\n",
    "        self.elite_size = elite_size\n",
    "        self.new_members = new_members\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.mutation_strength = mutation_strength\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.train_data = train_data\n",
    "\n",
    "        # Convert training data to tensors once\n",
    "        self.input_tensor = torch.tensor([data['input'] for data in train_data], dtype=torch.float32).to(DEVICE)\n",
    "        self.output_tensor = torch.tensor([data['output'] for data in train_data], dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "        # Create initial population\n",
    "        self.population = []\n",
    "        for _ in range(population_size):\n",
    "            network = SimpleNeuralNetwork(\n",
    "                input_size=input_size,\n",
    "                output_size=output_size,\n",
    "                hidden_layers=hidden_layers,\n",
    "            )\n",
    "            self.population.append(network)\n",
    "\n",
    "    def evaluate(\n",
    "        self,\n",
    "    ) -> List[Tuple[SimpleNeuralNetwork, int, float]]:\n",
    "        if DEVICE.type == \"cuda\" or DEVICE.type == \"mps\":\n",
    "            # GPU evaluation - process all networks sequentially since GPU handles parallelization\n",
    "            results = []\n",
    "            for network in self.population:\n",
    "                network.eval()\n",
    "                with torch.no_grad():\n",
    "                    predictions = network(self.input_tensor)\n",
    "                    predictions = (predictions > 0.5).float()\n",
    "                    accuracy = (predictions == self.output_tensor).float().mean().item()\n",
    "                    results.append((network, accuracy))\n",
    "            return results\n",
    "        else:\n",
    "            # CPU evaluation - use joblib for parallel processing\n",
    "            def eval_network(network: SimpleNeuralNetwork):\n",
    "                network.eval()\n",
    "                scores = []\n",
    "                with torch.no_grad():\n",
    "                    for test in self.train_data:\n",
    "                        input_values = test['input']\n",
    "                        prediction = network.forward(input_values)\n",
    "                        prediction = True if prediction[0] > .5 else False\n",
    "                        reality = True if test['output'][0] == 1.0 else False\n",
    "                        scores.append(1 if prediction == reality else 0)\n",
    "                return (network, sum(scores) / len(scores))\n",
    "\n",
    "            results = Parallel(n_jobs=joblib.cpu_count())(\n",
    "                delayed(eval_network)(net) for net in self.population\n",
    "            )\n",
    "            return results\n",
    "\n",
    "    def select_and_breed(\n",
    "        self, evaluated: List[Tuple[SimpleNeuralNetwork, int, float]]\n",
    "    ) -> None:\n",
    "        # Sort by score descending\n",
    "        evaluated.sort(key=lambda x: x[1], reverse=True)\n",
    "        elite = evaluated[: self.elite_size]\n",
    "\n",
    "        new_population = []\n",
    "        # Keep elite networks\n",
    "        for net, _ in elite:\n",
    "            new_population.append(net)\n",
    "\n",
    "        # Create offspring by mutating elite networks\n",
    "        while len(new_population) < self.population_size:\n",
    "            parent = random.choice(elite)[0]\n",
    "\n",
    "            # Create a child by copying the parent's state\n",
    "            child = copy.deepcopy(parent)\n",
    "\n",
    "            # Mutate the child\n",
    "            child.mutate(self.mutation_rate, self.mutation_strength)\n",
    "            new_population.append(child)\n",
    "\n",
    "        # Add random new members\n",
    "        for _ in range(self.new_members):\n",
    "            network = SimpleNeuralNetwork(hidden_layers=self.hidden_layers, input_size=self.input_size, output_size=self.output_size)\n",
    "            new_population.append(network)\n",
    "\n",
    "        self.population = new_population\n",
    "\n",
    "    def run_generation(\n",
    "        self,\n",
    "    ) -> Tuple[List[SimpleNeuralNetwork], float]:\n",
    "        evaluated = self.evaluate()\n",
    "        best_precision = max(precision for _, precision in evaluated)\n",
    "\n",
    "        self.select_and_breed(evaluated)\n",
    "\n",
    "        return self.population, best_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_network(network: SimpleNeuralNetwork, filename: str):\n",
    "    torch.save(network.state_dict(), filename)\n",
    "\n",
    "\n",
    "def load_network(filename: str, hidden_layers: List[int]) -> SimpleNeuralNetwork:\n",
    "    network = SimpleNeuralNetwork(hidden_layers=hidden_layers)\n",
    "    network.load_state_dict(torch.load(filename, map_location=DEVICE))\n",
    "    network.to(DEVICE)\n",
    "    return network\n",
    "\n",
    "\n",
    "def save_population(population: List[SimpleNeuralNetwork], filename: str):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(population, f)\n",
    "\n",
    "\n",
    "def load_population(filename: str) -> List[SimpleNeuralNetwork]:\n",
    "    with open(filename, \"rb\") as f:\n",
    "        population = pickle.load(f)\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T12:19:47.931825Z",
     "iopub.status.busy": "2025-10-29T12:19:47.931490Z",
     "iopub.status.idle": "2025-10-29T12:19:47.939072Z",
     "shell.execute_reply": "2025-10-29T12:19:47.938169Z",
     "shell.execute_reply.started": "2025-10-29T12:19:47.931801Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving networks to folder: networks/16_8_4\n",
      "Epoch 1 starting...\n",
      "Epoch: 1 1/1000 - Best Precision: 0.7969\n",
      "Epoch: 1 2/1000 - Best Precision: 0.7969\n",
      "Epoch: 1 3/1000 - Best Precision: 0.7969\n",
      "Epoch: 1 4/1000 - Best Precision: 0.7969\n",
      "Epoch: 1 5/1000 - Best Precision: 0.7969\n",
      "Epoch: 1 6/1000 - Best Precision: 0.7969\n",
      "Epoch: 1 7/1000 - Best Precision: 0.8047\n",
      "Epoch: 1 8/1000 - Best Precision: 0.8047\n",
      "Epoch: 1 9/1000 - Best Precision: 0.8047\n",
      "Epoch: 1 10/1000 - Best Precision: 0.8092\n",
      "Epoch: 1 11/1000 - Best Precision: 0.8092\n",
      "Epoch: 1 12/1000 - Best Precision: 0.8092\n",
      "Epoch: 1 13/1000 - Best Precision: 0.8114\n",
      "Epoch: 1 14/1000 - Best Precision: 0.8114\n",
      "Epoch: 1 15/1000 - Best Precision: 0.8171\n",
      "Epoch: 1 16/1000 - Best Precision: 0.8171\n",
      "Epoch: 1 17/1000 - Best Precision: 0.8171\n",
      "Epoch: 1 18/1000 - Best Precision: 0.8171\n",
      "Epoch: 1 19/1000 - Best Precision: 0.8215\n",
      "Epoch: 1 20/1000 - Best Precision: 0.8215\n",
      "Epoch: 1 21/1000 - Best Precision: 0.8215\n",
      "Epoch: 1 22/1000 - Best Precision: 0.8215\n",
      "Epoch: 1 23/1000 - Best Precision: 0.8215\n",
      "Epoch: 1 24/1000 - Best Precision: 0.8215\n",
      "Epoch: 1 25/1000 - Best Precision: 0.8215\n",
      "Epoch: 1 26/1000 - Best Precision: 0.8215\n",
      "Epoch: 1 27/1000 - Best Precision: 0.8215\n",
      "Epoch: 1 28/1000 - Best Precision: 0.8215\n",
      "Epoch: 1 29/1000 - Best Precision: 0.8215\n",
      "Epoch: 1 30/1000 - Best Precision: 0.8215\n",
      "Epoch: 1 31/1000 - Best Precision: 0.8215\n",
      "Epoch: 1 32/1000 - Best Precision: 0.8227\n",
      "Epoch: 1 33/1000 - Best Precision: 0.8227\n",
      "Epoch: 1 34/1000 - Best Precision: 0.8272\n",
      "Epoch: 1 35/1000 - Best Precision: 0.8272\n",
      "Epoch: 1 36/1000 - Best Precision: 0.8272\n",
      "Epoch: 1 37/1000 - Best Precision: 0.8272\n",
      "Epoch: 1 38/1000 - Best Precision: 0.8272\n",
      "Epoch: 1 39/1000 - Best Precision: 0.8272\n",
      "Epoch: 1 40/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 41/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 42/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 43/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 44/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 45/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 46/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 47/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 48/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 49/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 50/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 51/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 52/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 53/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 54/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 55/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 56/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 57/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 58/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 59/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 60/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 61/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 62/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 63/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 64/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 65/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 66/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 67/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 68/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 69/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 70/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 71/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 72/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 73/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 74/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 75/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 76/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 77/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 78/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 79/1000 - Best Precision: 0.8305\n",
      "Epoch: 1 80/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 81/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 82/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 83/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 84/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 85/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 86/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 87/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 88/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 89/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 90/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 91/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 92/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 93/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 94/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 95/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 96/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 97/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 98/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 99/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 100/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 101/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 102/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 103/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 104/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 105/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 106/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 107/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 108/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 109/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 110/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 111/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 112/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 113/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 114/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 115/1000 - Best Precision: 0.8339\n",
      "Epoch: 1 116/1000 - Best Precision: 0.8350\n",
      "Epoch: 1 117/1000 - Best Precision: 0.8350\n",
      "Epoch: 1 118/1000 - Best Precision: 0.8361\n",
      "Epoch: 1 119/1000 - Best Precision: 0.8361\n",
      "Epoch: 1 120/1000 - Best Precision: 0.8361\n",
      "Epoch: 1 121/1000 - Best Precision: 0.8361\n",
      "Epoch: 1 122/1000 - Best Precision: 0.8361\n",
      "Epoch: 1 123/1000 - Best Precision: 0.8361\n",
      "Epoch: 1 124/1000 - Best Precision: 0.8361\n",
      "Epoch: 1 125/1000 - Best Precision: 0.8361\n",
      "Epoch: 1 126/1000 - Best Precision: 0.8361\n",
      "Epoch: 1 127/1000 - Best Precision: 0.8361\n",
      "Epoch: 1 128/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 129/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 130/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 131/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 132/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 133/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 134/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 135/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 136/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 137/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 138/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 139/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 140/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 141/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 142/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 143/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 144/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 145/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 146/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 147/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 148/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 149/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 150/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 151/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 152/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 153/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 154/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 155/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 156/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 157/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 158/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 159/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 160/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 161/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 162/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 163/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 164/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 165/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 166/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 167/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 168/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 169/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 170/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 171/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 172/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 173/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 174/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 175/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 176/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 177/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 178/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 179/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 180/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 181/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 182/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 183/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 184/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 185/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 186/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 187/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 188/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 189/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 190/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 191/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 192/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 193/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 194/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 195/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 196/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 197/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 198/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 199/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 200/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 201/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 202/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 203/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 204/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 205/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 206/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 207/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 208/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 209/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 210/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 211/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 212/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 213/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 214/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 215/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 216/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 217/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 218/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 219/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 220/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 221/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 222/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 223/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 224/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 225/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 226/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 227/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 228/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 229/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 230/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 231/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 232/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 233/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 234/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 235/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 236/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 237/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 238/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 239/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 240/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 241/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 242/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 243/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 244/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 245/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 246/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 247/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 248/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 249/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 250/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 251/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 252/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 253/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 254/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 255/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 256/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 257/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 258/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 259/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 260/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 261/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 262/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 263/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 264/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 265/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 266/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 267/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 268/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 269/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 270/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 271/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 272/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 273/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 274/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 275/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 276/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 277/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 278/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 279/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 280/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 281/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 282/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 283/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 284/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 285/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 286/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 287/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 288/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 289/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 290/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 291/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 292/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 293/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 294/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 295/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 296/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 297/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 298/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 299/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 300/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 301/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 302/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 303/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 304/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 305/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 306/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 307/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 308/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 309/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 310/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 311/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 312/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 313/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 314/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 315/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 316/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 317/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 318/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 319/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 320/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 321/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 322/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 323/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 324/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 325/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 326/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 327/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 328/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 329/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 330/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 331/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 332/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 333/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 334/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 335/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 336/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 337/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 338/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 339/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 340/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 341/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 342/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 343/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 344/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 345/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 346/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 347/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 348/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 349/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 350/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 351/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 352/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 353/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 354/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 355/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 356/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 357/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 358/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 359/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 360/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 361/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 362/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 363/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 364/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 365/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 366/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 367/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 368/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 369/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 370/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 371/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 372/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 373/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 374/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 375/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 376/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 377/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 378/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 379/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 380/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 381/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 382/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 383/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 384/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 385/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 386/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 387/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 388/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 389/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 390/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 391/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 392/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 393/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 394/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 395/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 396/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 397/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 398/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 399/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 400/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 401/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 402/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 403/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 404/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 405/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 406/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 407/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 408/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 409/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 410/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 411/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 412/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 413/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 414/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 415/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 416/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 417/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 418/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 419/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 420/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 421/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 422/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 423/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 424/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 425/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 426/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 427/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 428/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 429/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 430/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 431/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 432/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 433/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 434/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 435/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 436/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 437/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 438/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 439/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 440/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 441/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 442/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 443/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 444/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 445/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 446/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 447/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 448/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 449/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 450/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 451/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 452/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 453/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 454/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 455/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 456/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 457/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 458/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 459/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 460/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 461/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 462/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 463/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 464/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 465/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 466/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 467/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 468/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 469/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 470/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 471/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 472/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 473/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 474/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 475/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 476/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 477/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 478/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 479/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 480/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 481/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 482/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 483/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 484/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 485/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 486/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 487/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 488/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 489/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 490/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 491/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 492/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 493/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 494/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 495/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 496/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 497/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 498/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 499/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 500/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 501/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 502/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 503/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 504/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 505/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 506/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 507/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 508/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 509/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 510/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 511/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 512/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 513/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 514/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 515/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 516/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 517/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 518/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 519/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 520/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 521/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 522/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 523/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 524/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 525/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 526/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 527/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 528/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 529/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 530/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 531/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 532/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 533/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 534/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 535/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 536/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 537/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 538/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 539/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 540/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 541/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 542/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 543/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 544/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 545/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 546/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 547/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 548/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 549/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 550/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 551/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 552/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 553/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 554/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 555/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 556/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 557/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 558/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 559/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 560/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 561/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 562/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 563/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 564/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 565/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 566/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 567/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 568/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 569/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 570/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 571/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 572/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 573/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 574/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 575/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 576/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 577/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 578/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 579/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 580/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 581/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 582/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 583/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 584/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 585/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 586/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 587/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 588/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 589/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 590/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 591/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 592/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 593/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 594/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 595/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 596/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 597/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 598/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 599/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 600/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 601/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 602/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 603/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 604/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 605/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 606/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 607/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 608/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 609/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 610/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 611/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 612/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 613/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 614/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 615/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 616/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 617/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 618/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 619/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 620/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 621/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 622/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 623/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 624/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 625/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 626/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 627/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 628/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 629/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 630/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 631/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 632/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 633/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 634/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 635/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 636/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 637/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 638/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 639/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 640/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 641/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 642/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 643/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 644/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 645/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 646/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 647/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 648/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 649/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 650/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 651/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 652/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 653/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 654/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 655/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 656/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 657/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 658/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 659/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 660/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 661/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 662/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 663/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 664/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 665/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 666/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 667/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 668/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 669/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 670/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 671/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 672/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 673/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 674/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 675/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 676/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 677/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 678/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 679/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 680/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 681/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 682/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 683/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 684/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 685/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 686/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 687/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 688/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 689/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 690/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 691/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 692/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 693/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 694/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 695/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 696/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 697/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 698/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 699/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 700/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 701/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 702/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 703/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 704/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 705/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 706/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 707/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 708/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 709/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 710/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 711/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 712/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 713/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 714/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 715/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 716/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 717/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 718/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 719/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 720/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 721/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 722/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 723/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 724/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 725/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 726/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 727/1000 - Best Precision: 0.8373\n",
      "Epoch: 1 728/1000 - Best Precision: 0.8373\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "generations = 1000\n",
    "hidden_layers = [16, 8, 4]\n",
    "mutation_rate = 0.5\n",
    "mutation_strength = 0.25\n",
    "\n",
    "folder = f\"networks/{'_'.join(str(x) for x in hidden_layers)}\"\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "print(f\"Saving networks to folder: {folder}\")\n",
    "\n",
    "scores_best = []\n",
    "\n",
    "optimizer = EvolutionaryOptimizer(\n",
    "    population_size=100,\n",
    "    elite_size=20,\n",
    "    new_members=100,\n",
    "    mutation_rate=mutation_rate,\n",
    "    mutation_strength=mutation_strength,\n",
    "    input_size=7,\n",
    "    hidden_layers=hidden_layers,\n",
    "    output_size=1,\n",
    "    train_data=train_data\n",
    ")\n",
    "\n",
    "def mutation_decay(x, mu0=0.25, k=3.0):\n",
    "    return mu0 * np.exp(-k * x)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "epoch = 0\n",
    "while True:\n",
    "    print(f\"Epoch {epoch+1} starting...\")\n",
    "    epoch += 1\n",
    "    for gen in range(generations):\n",
    "        optimizer.mutation_strength = mutation_decay(\n",
    "            gen / generations, k=4, mu0=mutation_strength\n",
    "        )\n",
    "        optimizer.mutation_rate = mutation_decay(gen / generations, k=4, mu0=mutation_rate)\n",
    "\n",
    "        (population, best_precision) = optimizer.run_generation()\n",
    "        print(f\"Epoch: {epoch} {gen+1}/{generations} - Best Precision: {best_precision:.4f}\")\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    duration = str(timedelta(seconds=(elapsed_time)))\n",
    "    print(f\"Epoch {epoch} completed after {duration}\")\n",
    "    save_population(optimizer.population, f\"{folder}/population_epoch_{epoch}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate prediction\n",
    "network = optimizer.population[0]\n",
    "\n",
    "predictions = []\n",
    "for test in test_data:\n",
    "    input_values = test['input']\n",
    "    prediction = network.forward(input_values)\n",
    "    prediction = prediction.cpu()\n",
    "    prediction = True if prediction[0] > .5 else False\n",
    "    # print(f\"Passenger ID: {test['id']}, Survived: {1 if prediction else 0}\")\n",
    "    predictions.append([test['id'], 1 if prediction else 0])\n",
    "\n",
    "# Save predictions to CSV\n",
    "with open(\"submission.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    fieldnames = [\"PassengerId\", \"Survived\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for pid, survived in predictions:\n",
    "        writer.writerow({\"PassengerId\": pid, \"Survived\": survived})\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "titanic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
